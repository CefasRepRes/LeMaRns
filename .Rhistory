view_NAA(series_name, NAA, req_cruise, harbour)
write.csv(view_NAA(series_name, NAA, req_cruise, harbour), file = "NAA_2_02_Inside.csv")
write.csv(view_NAA(series_name, NAA, req_cruise, "Outside"), file = "NAA_2_02_Outside.csv")
head(survey_data)
unique(survey_data$fldCruiseName, survey_data$fldPrimeStation)
unique(survey_data[c("fldCruiseName", "fldPrimeStation")])
write.csv(unique(survey_data[c("fldCruiseName", "fldPrimeStation")]), file = "length_stations.csv")
head(age_data)
################################################################################
# SEA BASS RECRUITMENT INDICES
# R code developed by Hayley Bannister 30/01/2019
################################################################################
# Set up workspace
rm(list = ls())
setwd("\\\\lowfilecds\\function\\Sea bass management\\Surveys\\Solent\\Automated_recruitment_index\\")
# Install and load required packages
req_packages <- c("DBI", "tidyverse", "lubridate", "maps", "measurements",
"viridis", "rgdal", "mapproj")
for (i in req_packages) {
if (!i %in% installed.packages()[, "Package"]) {install.packages(i)}
}
# Source functions required to calculate the recruitment indices
source("R/extract_survey_data.R")
source("R/extract_age_data.R")
source("R/length_distributions.R")
source("R/plot_length_distributions.R")
source("R/create_ALK.R")
source("R/view_ALK.R")
source("R/plot_ALK.R")
source("R/calc_NAA.R")
source("R/view_NAA.R")
source("R/standardise_NAA.R")
source("R/view_standardised_NAA.R")
source("R/calc_abundance_index.R")
source("R/calc_recruit_index.R")
################################################################################
# Set series name, cruise name and the ages to be included in the recruitment
# index
series_name <- "SOLENT"
req_ages_for_index <- 2:4
req_months <- c(8, 9, 10) # months that required cruises occurred in
req_cruise <- "AMAR 2/02" # only used for looking at the ALK/NAA for a
# specific cruise
req_year <- 2002 # only used for looking at the standardised NAA for a specific
# year
prime_stations <- read.csv("Data/SolentPrimeStations.csv")
harbour <- "Inside" # only used for looking at the ALK/NAA for a specific
# year
################################################################################
# Open connection to FSS database (using Windows authentication)
library(DBI)
FSS <- dbConnect(odbc::odbc(), .connection_string = "Driver={SQL Server};
Server=FSSdbLive; database=FSS; trusted_connection=true")
# Extract survey data from the FSS database and filter by series name
survey_data <- extract_survey_data(FSS, series_name, prime_stations,
req_months)
# Determine length distributions by year
lds <- length_distributions(survey_data, series_name, req_years =
unique(survey_data$Year))
test <- lds %>%
filter(fldCruiseName == req_cruise) %>%
group_by(fldLengthGroup, Location) %>%
summarise(Total = sum(Total)) %>%
arrange(Location)
data.frame(test)
# Plot length distributions by year
p1 <- plot_length_distributions(series_name, lds)
p1
# Extract age data from the FSS database and filter by cruise name
cruise_name <- unique(survey_data$fldCruiseName)
age_data <- extract_age_data(FSS, series_name, cruise_name, prime_stations)
# Create Age-Length Key (ALK)
ALK <- create_ALK(series_name, lds, age_data)
# View ALK for a specific cruise in the same format as the excel spreadsheets
view_ALK(series_name, ALK, req_cruise, harbour)
# Plot ALKs by year
p2 <- plot_ALK(series_name, ALK, harbour)
p2
# Determine Numbers At Age (NAA) by station
NAA <- calc_NAA(series_name, lds, ALK)
# View numbers at age for a specific cruise in the same format as the excel
# spreadsheets
view_NAA(series_name, NAA, req_cruise, harbour)
# Standardise numbers at age to 10 min tow and average over duplicate surveys
standardised_NAA <- standardise_NAA(survey_data, NAA)
tow_duration
write.csv(tow_duration, file = "tow_durations.csv")
head(survey_data)
head(survey_data$fldTowDuration)
unique(survey_data[c("fldCruiseName", "fldPrimeStation", fldTowDuration)])
unique(survey_data[c("fldCruiseName", "fldCruiseStationNumber", fldTowDuration)])
unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", fldTowDuration)])
survey_data$fldCruiseName
survey_data$fldCruiseStationNumber
survey_data$fldTowDuration
unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", fldTowDuration)])
survey_data[, c("fldCruiseName", "fldCruiseStationNumber", fldTowDuration)
]
unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", "fldTowDuration")])
write.csv(unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", "fldTowDuration")]), file="stations_by_cruise_name.csv"
write.csv(unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", "fldTowDuration")]), file="tow_durations.csv)"
write.csv(unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", "fldTowDuration")]), file="tow_durations.csv")
write.csv(unique(survey_data[, c("fldCruiseName", "fldCruiseStationNumber", "fldTowDuration")]), file="tow_durations.csv")
################################################################################
# SEA BASS RECRUITMENT INDICES
# R code developed by Hayley Bannister 30/01/2019
################################################################################
# Set up workspace
rm(list = ls())
setwd("\\\\lowfilecds\\function\\Sea bass management\\Surveys\\Solent\\Automated_recruitment_index\\")
# Install and load required packages
req_packages <- c("DBI", "tidyverse", "lubridate", "maps", "measurements",
"viridis", "rgdal", "mapproj")
for (i in req_packages) {
if (!i %in% installed.packages()[, "Package"]) {install.packages(i)}
}
# Source functions required to calculate the recruitment indices
source("R/extract_survey_data.R")
source("R/extract_age_data.R")
source("R/length_distributions.R")
source("R/plot_length_distributions.R")
source("R/create_ALK.R")
source("R/view_ALK.R")
source("R/plot_ALK.R")
source("R/calc_NAA.R")
source("R/view_NAA.R")
source("R/standardise_NAA.R")
source("R/view_standardised_NAA.R")
source("R/calc_abundance_index.R")
source("R/calc_recruit_index.R")
################################################################################
# Set series name, cruise name and the ages to be included in the recruitment
# index
series_name <- "SOLENT"
req_ages_for_index <- 2:4
req_months <- c(5, 6, 7) # months that required cruises occurred in
req_cruise <- "AMAR 1/01" # only used for looking at the ALK/NAA for a
# specific cruise
req_year <- 2001 # only used for looking at the standardised NAA for a specific
# year
prime_stations <- read.csv("Data/SolentPrimeStations.csv")
harbour <- "Inside" # only used for looking at the ALK/NAA for a specific
# year
################################################################################
# Open connection to FSS database (using Windows authentication)
library(DBI)
FSS <- dbConnect(odbc::odbc(), .connection_string = "Driver={SQL Server};
Server=FSSdbLive; database=FSS; trusted_connection=true")
# Extract survey data from the FSS database and filter by series name
survey_data <- extract_survey_data(FSS, series_name, prime_stations,
req_months)
# Determine length distributions by year
lds <- length_distributions(survey_data, series_name, req_years =
unique(survey_data$Year))
test <- lds %>%
filter(fldCruiseName == req_cruise) %>%
group_by(fldLengthGroup, Location) %>%
summarise(Total = sum(Total)) %>%
arrange(Location)
data.frame(test)
# Plot length distributions by year
p1 <- plot_length_distributions(series_name, lds)
p1
# Extract age data from the FSS database and filter by cruise name
cruise_name <- unique(survey_data$fldCruiseName)
age_data <- extract_age_data(FSS, series_name, cruise_name, prime_stations)
# Create Age-Length Key (ALK)
ALK <- create_ALK(series_name, lds, age_data)
# View ALK for a specific cruise in the same format as the excel spreadsheets
view_ALK(series_name, ALK, req_cruise, harbour)
# Plot ALKs by year
p2 <- plot_ALK(series_name, ALK, harbour)
p2
# Determine Numbers At Age (NAA) by station
NAA <- calc_NAA(series_name, lds, ALK)
# View numbers at age for a specific cruise in the same format as the excel
# spreadsheets
view_NAA(series_name, NAA, req_cruise, harbour)
# Standardise numbers at age to 10 min tow and average over duplicate surveys
standardised_NAA <- standardise_NAA(survey_data, NAA)
# View standardised NAA for a specific cruise in the same format as the excel
# spreadsheets
view_standardised_NAA(standardised_NAA, req_year)
# Calculate abundance index
abun_index <- calc_abundance_index(survey_data, standardised_NAA,
req_ages_for_index)
abun_index
write.csv(abun_index, file="solent_abun_index.csv")
devtools::load_all("Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns")
warnings()
devtools::load_all(".")
NS_params_n <- LeMansParam(NS_par, tau=NS_tau, eta=eta, L50=L50, other=1e11)
model_run_n_init <- run_LeMans(NS_params_n,years=50)
### set the initial state
N0 <- model_run_n_init@N[,,501]
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
mean(tail(colSums(nash@Catch[,i,]),10))/1e6
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=total_catch)
NS_params_n <- LeMansParam(NS_par, tau=NS_tau, eta=eta, L50=L50, other=1e12)
model_run_n_init <- run_LeMans(NS_params_n,years=50)
### set the initial state
N0 <- model_run_n_init@N[,,501]
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=total_catch)
?run_LeMans
model_run_n_init <- run_LeMans(NS_params_n,years=50,intercept=1e20)
### set the initial state
N0 <- model_run_n_init@N[,,501]
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=total_catch)
model_run_n_init <- run_LeMans(NS_params_n,years=50,intercept=1e11)
### set the initial state
N0 <- model_run_n_init@N[,,501]
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=total_catch)
NS_params_n <- LeMansParam(NS_par, tau=NS_tau, eta=eta, L50=L50, other=1e11)
model_run_n_init <- run_LeMans(NS_params_n,years=50)
### set the initial state
N0 <- model_run_n_init@N[,,501]
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=total_catch)
load("Y:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/a_b.Rdata")
new_ab
NS_par
NS_par$a <- new_ab$a
NS_par$b <- new_ab$b
NS_par
NS_params_n <- LeMansParam(NS_par, tau=NS_tau, eta=eta, L50=L50, other=1e11)
model_run_n_init <- run_LeMans(NS_params_n,years=50)
plot_SSB(inputs=NS_params_n,outputs=model_run_n_init)
N0 <- model_run_n_init@N[,,501]
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
eff
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=total_catch)
data.frame(species=NS_params_n@species_names,Nash_catch=round(total_catch,2))
NS_params_n <- LeMansParam(NS_par, tau=NS_tau, eta=eta, L50=L50, other=1e12)
model_run_n_init <- run_LeMans(NS_params_n,years=50)
### set the initial state
N0 <- model_run_n_init@N[,,501]
plot_SSB(inputs=NS_params_n,outputs=model_run_n_init)
calc_catch<-function(x,i,eff){
eff[i] <- x
tmp<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
return(-mean(tail(colSums(tmp@Catch[,i,]),10))) ## minus because we want to use the optim function
}
stat <- rep(FALSE,21)
eff <- c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
while(any(stat==FALSE)){
for (i in 1:21){
opts <- optim(eff[i],calc_catch,i=i,eff=eff,method = "Brent",lower=0,upper=2)
stat[i] <- abs(eff[i] - opts$par) < 0.01
eff[i] <- opts$par
}
}
eff
nash<-run_LeMans(NS_params_n,N0=N0,years=20,effort=matrix(eff,nrow=20,ncol=21,byrow=T))
plot_SSB(inputs=NS_params_n,outputs = nash)
total_catch <- colMeans(apply(nash@Catch[,,192:201],2,colSums))/1e6
data.frame(species=NS_params_n@species_names,Nash_catch=round(total_catch,2))
fmsy <-c(1.3,0.35,0.35,0.72,0.6,0.41,0.25,0.5,0.33,0.22,0.32,0.21,0.27,0.27,0.25,0.15,0.30,0.11,0.1,0.19,0.3)
plot(eff, fmsy)
abline(a=0,b=1)
eff
NS_params_n <- LeMansParam(NS_par, tau=NS_tau, eta=eta, L50=L50, other=5e11)
model_run_n_init <- run_LeMans(NS_params_n,years=50)
### set the initial state
N0 <- model_run_n_init@N[,,501]
plot_SSB(inputs=NS_params_n,outputs = nash)
plot_SSB(inputs=NS_params_n,outputs=model_run_n_init)
tools::package_native_routine_registration_skeleton()
?package_native_routine_registration_skeleton
?package_native_routine_registration_skeleton(dir="Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns")
tools::package_native_routine_registration_skeleton(dir="Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns")
tools::package_native_routine_registration_skeleton(dir="Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns/")
tools::package_native_routine_registration_skeleton(dir="Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns/R")
devtools::check()
install.packages("qpdf")
devtools::check()
devtools::check()
library(LeMaRns)
spelling::spell_check_package("Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns/LeMaRns.pdf")
install.packages("spelling")
install.packages("spelling")
library(spelling)
spelling::spell_check_package("Z:/C7413_H2020 PANDORA/Working_Area/R_LeMANS/LeMaRns/LeMaRns.pdf")
spelling::spell_check_package("LeMaRns.pdf")
spelling::spell_check_package()
library(LeMaRns)
spelling::spell_check_package()
